2024-04-17 20:09:35.925694: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-17 20:10:19.354327: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-04-17 20:10:19.356036: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-04-17 20:10:19.356092: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
/home/tzhu38/miniconda3/envs/vid2seq/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5.py:173: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  FutureWarning,
load Vid2Seq model
here  100
tokenizer len:  32200
model len:  768
loading visual backbone
extracting visual features
visual features extracted
load ASR
ASR to tokens
forward to Vid2Seq
decode results
{'sentence': 'Intro.', 'timestamp': [0.0, 10.843484848484847]}
{'sentence': 'Add sugar and apple cider vinegar to a bowl.', 'timestamp': [10.843484848484847, 28.193060606060605]}
{'sentence': 'Add apple cider vinegar and apple cider vinegar to the bowl.', 'timestamp': [28.193060606060605, 41.20524242424242]}
{'sentence': 'Add apple cider vinegar and apple cider vinegar to the bowl.', 'timestamp': [41.20524242424242, 56.38612121212121]}
{'sentence': 'Add apple cider vinegar and apple cider vinegar to the bowl.', 'timestamp': [56.38612121212121, 71.567]}
{'sentence': 'Add apple cider vinegar and apple cider vinegar to the bowl.', 'timestamp': [71.567, 86.74787878787878]}
{'sentence': 'Add apple cider vinegar and apple cider vinegar to the bowl.', 'timestamp': [91.08527272727272, 106.26615151515152]}
{'sentence': 'Add apple cider vinegar and apple cider vinegar to the bowl.', 'timestamp': [106.26615151515152, 123.61572727272727]}
{'sentence': 'Add apple cider vinegar and apple cider vinegar to the bowl.', 'timestamp': [123.61572727272727, 145.30269696969697]}
{'sentence': 'Add apple cider vinegar and apple cider vinegar to the bowl.', 'timestamp': [147.47139393939395, 158.31487878787877]}
{'sentence': 'Add apple cider vinegar and apple cider vinegar to the bowl.', 'timestamp': [158.31487878787877, 171.32706060606063]}
{'sentence': 'Add apple cider vinegar and apple cider vinegar to the bowl.', 'timestamp': [173.49575757575755, 184.33924242424243]}
{'sentence': 'Add apple cider vinegar and apple cider vinegar to the bowl.', 'timestamp': [184.33924242424243, 195.18272727272728]}
